{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006129cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from a CSV file\n",
    "data = pd.read_csv('./miRNA_name.csv')\n",
    "\n",
    "# Extract the 'Interactor1' column data\n",
    "id1_data = data['Interactor1']\n",
    "\n",
    "# Construct a string with each element prefixed by ' OR '\n",
    "formatted_string = ' OR '.join(id1_data)\n",
    "\n",
    "# Save the formatted string to a text file\n",
    "with open(\"output.txt\", \"w\") as file:\n",
    "    file.write(' OR ' + formatted_string)  # Prepend ' OR ' to the first item as well\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4184442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load data from a CSV file\n",
    "table1 = pd.read_csv('./miRNA_nc.csv', index_col=0)\n",
    "\n",
    "# Load FASTA sequence data\n",
    "with open('./miRNA_sequence.fasta', 'r') as fasta_file:\n",
    "    fasta_data = fasta_file.read()\n",
    "\n",
    "# Extract RNA sequence information from the FASTA data\n",
    "p_sequences = re.findall(r\">(.*?)(?=\\n)([\\s\\S]*?)(?=>|\\Z)\", fasta_data)\n",
    "\n",
    "# Create columns for sequence names and sequences\n",
    "p_seqname_list = [seq[0] for seq in p_sequences]\n",
    "p_sequences_list = [seq[1].replace('\\n', '') for seq in p_sequences]\n",
    "\n",
    "# Add a new column to store RNA sequences\n",
    "table1['r_seq'] = ''\n",
    "\n",
    "# Map sequences to table1 based on matching identifiers\n",
    "for index, row in table1.iterrows():\n",
    "    pattern = r'(NC_(\\d+)\\.(\\d+))'\n",
    "    protein_id = re.search(pattern, row['seq_id']).group(1)\n",
    "\n",
    "    # Find the sequence that matches the identifier and add it to the dataframe\n",
    "    try:\n",
    "        idx = p_seqname_list.index(protein_id)\n",
    "        table1.at[index, 'r_seq'] = p_sequences_list[idx][row['start_idx']:row['end_idx']]\n",
    "    except ValueError:\n",
    "        table1.at[index, 'r_seq'] = None\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "table1.to_csv('miRNA_sequence_nc.csv')\n",
    "\n",
    "# Check and print if any 'None' values exist in the 'r_seq' column\n",
    "column_has_none = table1['r_seq'].isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data from a text file\n",
    "with open('gene_result_rna.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Load data from a CSV file\n",
    "data_table1 = pd.read_csv('miRNA_name.csv', index_col=0)\n",
    "\n",
    "# Add new columns for sequence identifiers and indices\n",
    "data_table1['seq_id'] = None\n",
    "data_table1['start_idx'] = ''\n",
    "data_table1['end_idx'] = ''\n",
    "\n",
    "# Extract sequence information based on Interactor1\n",
    "for index, row in data_table1.iterrows():\n",
    "    interactor = row[\"Interactor1\"]\n",
    "    match = re.search(rf\"{re.escape(interactor)}\", text_data)\n",
    "    if match:\n",
    "        start_index = match.end()\n",
    "        match_xp = re.search(r'NC_\\d+\\.\\d+ \\((.*?)\\)', text_data[start_index:])\n",
    "        if match_xp:\n",
    "            matches = re.search(r'NC_(\\d+\\.\\d+) \\((\\d+)\\.\\.(\\d+)', match_xp.group(0))\n",
    "            nc_id, start_idx, end_idx = \"NC_\" + matches.group(1), matches.group(2), matches.group(3)\n",
    "            data_table1.at[index, 'seq_id'] = nc_id\n",
    "            data_table1.at[index, 'start_idx'] = start_idx\n",
    "            data_table1.at[index, 'end_idx'] = end_idx\n",
    "\n",
    "# Remove duplicates based on Interactor1\n",
    "data_table1 = data_table1.drop_duplicates(subset='Interactor1', keep='first')\n",
    "\n",
    "# Load another dataset\n",
    "data_table2 = data_table1.dropna(subset=['seq_id']).reset_index(drop=True)\n",
    "data_table2 = data_table2.drop_duplicates(subset='Interactor1', keep='first')\n",
    "\n",
    "# Prepare the array from another CSV for cleaning\n",
    "ass = np.array(pd.read_csv('ass.csv', index_col=0))\n",
    "\n",
    "# Remove rows corresponding to missing seq_id\n",
    "k_list = [k for k, seq_id in enumerate(data_table2['seq_id']) if seq_id is None]\n",
    "ass = np.delete(ass, k_list, axis=0)\n",
    "\n",
    "# Ensure the dataset directory exists\n",
    "if not os.path.exists('./dataset/'):\n",
    "    os.mkdir('./dataset/')\n",
    "\n",
    "# Save the cleaned array to CSV\n",
    "pd.DataFrame(ass).to_csv('./dataset/ass_del1.csv', index=False, header=False)\n",
    "print(pd.DataFrame(ass).shape)\n",
    "\n",
    "# Drop rows with missing seq_id in the data table and save\n",
    "data_table = data_table2.dropna(subset=['seq_id'])\n",
    "data_table.to_csv('miRNA_nc.csv')\n",
    "\n",
    "# Save sequence identifiers to a separate CSV\n",
    "data_table['seq_id'].to_csv('miRNA_id.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read CSV file containing data\n",
    "data = pd.read_csv('./protein_name.csv', index_col=None)\n",
    "\n",
    "# Save the last column of the data to a file\n",
    "data.iloc[:, -1].to_csv('protein_id.csv', index=False, header=None)\n",
    "\n",
    "# Read text data from multiple files and concatenate it\n",
    "text_files = ['gene_result (6).txt', 'gene_result (7).txt']\n",
    "text_data = ''\n",
    "for filename in text_files:\n",
    "    with open(filename, 'r') as file:\n",
    "        text_data += file.read()\n",
    "\n",
    "# Initialize a new column 'NP' with None values in the DataFrame\n",
    "data['NP'] = None\n",
    "\n",
    "# Iterate over each row to find the closest location for 'Interactor2' and extract the corresponding 'NP' value\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    interactor = row[\"Id2\"]\n",
    "    match = re.search(f\"geneid {interactor}\", text_data)\n",
    "    if match:\n",
    "        start_index = match.end()\n",
    "        match_xp = re.search(r'\"NP_(\\d+)\"', text_data[start_index:])\n",
    "        if match_xp:\n",
    "            np_number = 'NP_' + match_xp.group(1)\n",
    "            data.at[index, 'NP'] = np_number\n",
    "            # Optionally, handle 'version' if it's relevant\n",
    "            match_xp_v = re.search(r'version (\\d+)', text_data[start_index + match_xp.end():])\n",
    "            if match_xp_v:\n",
    "                np_number += '.' + match_xp_v.group(1)\n",
    "                data.at[index, 'NP'] = np_number\n",
    "\n",
    "# Save updated DataFrame with 'NP' numbers included\n",
    "data.to_csv('./protein_id_np.csv')\n",
    "\n",
    "# Load the updated table\n",
    "table_data = pd.read_csv('./protein_id_np.csv', index_col=0)\n",
    "table_data['NP'] = table_data['NP'].replace('', None)\n",
    "\n",
    "# Drop rows with missing 'NP' values\n",
    "table_data.dropna(subset=['NP'], inplace=True)\n",
    "\n",
    "# Save the cleaned data\n",
    "table_data.to_csv('./protein_id_np.csv')\n",
    "table_data['NP'].to_csv('./protein_np.csv', header=None, index=None)\n",
    "\n",
    "# Print the shape of the cleaned data\n",
    "print(f\"Cleaned data shape: {table_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d38e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch download from NCBI could be planned using \"https://www.ncbi.nlm.nih.gov/sites/batchentrez\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84dbeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read data from CSV files\n",
    "table1 = pd.read_csv('./protein_id_np.csv', index_col=0)\n",
    "\n",
    "# Read and concatenate FASTA sequence data from multiple files\n",
    "fasta_files = ['./sequence (10).fasta', './sequence (11).fasta']\n",
    "fasta_data = ''\n",
    "for fasta_file in fasta_files:\n",
    "    with open(fasta_file, 'r') as file:\n",
    "        fasta_data += file.read()\n",
    "\n",
    "# Extract protein sequences from FASTA data\n",
    "p_sequences = re.findall(r\">(.*?)(?=\\n)([\\s\\S]*?)(?=>|\\Z)\", fasta_data)\n",
    "\n",
    "# Add a new column for storing protein sequences\n",
    "table1['protein_seq'] = None\n",
    "\n",
    "# Map protein IDs from table to sequences extracted from FASTA data\n",
    "for index, row in table1.iterrows():\n",
    "    pattern = r'(NP_(\\d+))'\n",
    "    protein_id = re.search(pattern, row['NP']).group(1)\n",
    "\n",
    "    # Find and assign the corresponding protein sequence\n",
    "    for header, sequence in p_sequences:\n",
    "        if protein_id in header:\n",
    "            table1.at[index, 'protein_seq'] = sequence.replace('\\n', '')\n",
    "            break\n",
    "\n",
    "# Check for and report any rows with missing protein sequences\n",
    "column_has_none = table1['protein_seq'].isnull().any()\n",
    "print(f\"Column contains None values: {column_has_none}\")\n",
    "\n",
    "# Clean up the data by dropping rows with missing protein sequences\n",
    "table1 = table1.dropna(subset=['protein_seq'])\n",
    "table1 = table1.drop_duplicates(subset=['NP'])\n",
    "\n",
    "# Save the cleaned and processed data\n",
    "if not os.path.exists('./dataset/'):\n",
    "    os.mkdir('./dataset/')\n",
    "table1.to_csv('./dataset/protein_seq.csv')\n",
    "\n",
    "# Read another dataset and adjust it based on the existing protein IDs\n",
    "ass = pd.read_csv('./dataset/ass_del1.csv', index_col=None, header=None)\n",
    "selected_columns = table1['Protein_id'].dropna().astype(int)  # Ensure indices are integers\n",
    "ass = ass.iloc[:, selected_columns]\n",
    "ass.to_csv('./dataset/ass_del2.csv', header=None, index=None)\n",
    "\n",
    "print(f\"Processed and saved data with shape: {table1.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201845bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load text data\n",
    "with open('gene_result_rna.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Load table data from a CSV file\n",
    "data_table1 = pd.read_csv('miRNA_name.csv', index_col=0)\n",
    "\n",
    "# Initialize new columns for extracted data\n",
    "data_table1['seq_id'] = None\n",
    "data_table1['start_idx'] = ''\n",
    "data_table1['end_idx'] = ''\n",
    "\n",
    "# Extract sequence identifiers and indices using regular expressions\n",
    "for index, row in data_table1.iterrows():\n",
    "    interactor = row[\"Interactor1\"]\n",
    "    match = re.search(re.escape(interactor), text_data)\n",
    "    if match:\n",
    "        start_index = match.end()\n",
    "        match_xp = re.search(r'NC_\\d+\\.\\d+ \\((.*?)\\)', text_data[start_index:])\n",
    "        if match_xp:\n",
    "            matches = re.search(r'NC_(\\d+\\.\\d+) \\((\\d+)\\.\\.(\\d+)', match_xp.group(0))\n",
    "            if matches:\n",
    "                nc_id, start_idx, end_idx = \"NC_\" + matches.group(1), matches.group(2), matches.group(3)\n",
    "                data_table1.at[index, 'seq_id'] = nc_id\n",
    "                data_table1.at[index, 'start_idx'] = start_idx\n",
    "                data_table1.at[index, 'end_idx'] = end_idx\n",
    "\n",
    "# Remove rows without sequence IDs and drop duplicates based on 'Interactor1'\n",
    "data_table1.dropna(subset=['seq_id'], inplace=True)\n",
    "data_table1.drop_duplicates(subset='Interactor1', inplace=True)\n",
    "\n",
    "# Read another table for operations\n",
    "data_table = pd.read_csv('./human/m_ss.csv', index_col=None, header=None)\n",
    "\n",
    "# Identify duplicated entries\n",
    "duplicated_entries = data_table1.duplicated(subset='Interactor1', keep='first')\n",
    "\n",
    "# Drop these entries from the secondary data table\n",
    "cleaned_data = data_table.drop(index=duplicated_entries[duplicated_entries].index)\n",
    "\n",
    "# Save the cleaned data\n",
    "cleaned_data.to_csv('./l_ss.csv', index=False, header=False)\n",
    "\n",
    "# Load additional data\n",
    "ass = np.array(pd.read_csv('ass.csv', index_col=0))\n",
    "\n",
    "# Remove rows corresponding to None sequence IDs\n",
    "none_idx = [idx for idx, seq_id in enumerate(data_table1['seq_id']) if seq_id is None]\n",
    "cleaned_ass = np.delete(ass, none_idx, axis=0)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = './dataset/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "# Save the further cleaned data\n",
    "pd.DataFrame(cleaned_ass).to_csv(f'{output_dir}ass_del1.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1aeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def GIP_kernel(Asso_RNA_Dis):\n",
    "    def getGosiR(Asso_RNA_Dis):\n",
    "        \"\"\" Calculate the normalization constant 'r' for the Gaussian Kernel. \"\"\"\n",
    "        # Calculate the sum of squared norms of each row\n",
    "        squared_norms = np.sum(np.square(np.linalg.norm(Asso_RNA_Dis, axis=1)))\n",
    "        # Compute 'r' as the average of these squared norms\n",
    "        r = squared_norms / Asso_RNA_Dis.shape[0]\n",
    "        return r\n",
    "    \n",
    "    # Number of entities (RNA/Disease)\n",
    "    nc = Asso_RNA_Dis.shape[0]\n",
    "    # Initialize the result matrix\n",
    "    matrix = np.zeros((nc, nc))\n",
    "    # Calculate the normalization constant 'r'\n",
    "    r = getGosiR(Asso_RNA_Dis)\n",
    "    \n",
    "    # Calculate the GIP kernel matrix\n",
    "    for i in range(nc):\n",
    "        for j in range(nc):\n",
    "            # Calculate the squared Euclidean distance between row vectors\n",
    "            squared_distance = np.square(np.linalg.norm(Asso_RNA_Dis[i, :] - Asso_RNA_Dis[j, :]))\n",
    "            if r == 0:\n",
    "                matrix[i, j] = 0\n",
    "            elif i == j:\n",
    "                matrix[i, j] = 1\n",
    "            else:\n",
    "                matrix[i, j] = np.exp(-squared_distance / r)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def main():\n",
    "    # Load data from CSV file into a NumPy array\n",
    "    A = np.array(pd.read_csv('./dataset/ass_del2.csv', header=None))\n",
    "\n",
    "    # Calculate GIP kernel for the matrix and its transpose\n",
    "    GIP_mr_sim = GIP_kernel(A)\n",
    "    GIP_d_sim = GIP_kernel(A.T)\n",
    "\n",
    "    # Save the computed GIP kernel matrices to CSV files\n",
    "    pd.DataFrame(GIP_mr_sim).to_csv('./dataset/m_gs.csv', header=None, index=None)\n",
    "    pd.DataFrame(GIP_d_sim).to_csv('./dataset/p_gs.csv', header=None, index=None)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
